{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional layer 1\n",
    "#when working with high dimensional inputs like images it is impractical to use a traditional feed forwrd nn\n",
    "#instead we connect each neuron to a local region of the input\n",
    "#make filters\n",
    "\n",
    "filter_size1= 5    #convolution filters are 5 x 5\n",
    "num_filters1= 16   #there are 16 5x5 filters\n",
    "\n",
    "filter_size2= 5    #convolutions 5x5\n",
    "num_filters= 36    # there are 36 5x5 filters\n",
    "\n",
    "#fully connected layer\n",
    "\n",
    "fc_size = 128 #number of neurons in fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-b59c64143e00>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\sfisc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\sfisc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\sfisc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\sfisc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sfisc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/MNIST\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sfisc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/MNIST', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we know that MNIST images are 28x28\n",
    "img_size = 28\n",
    "\n",
    "img_size_flat = img_size*img_size\n",
    "\n",
    "#tuple with height and width of images used to reshape arrays\n",
    "\n",
    "img_shape = (img_size,img_size)\n",
    "\n",
    "#number of color channels...since it's grayscale this value will be 1\n",
    "num_channels = 1\n",
    "\n",
    "#number of classed is 10...one for each digit\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        # Show the classes as the label on the x-axis.\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'cls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-159045f631f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcls_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplot_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclas_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'cls'"
     ]
    }
   ],
   "source": [
    "images = data.test.images[0:9]\n",
    "cls_true = data.test.cls[0:9]\n",
    "plot_images(images=images, cls_true=clas_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    #same as y intercept\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#has pooling and ReLU built into it...think of it as one block\n",
    "def new_conv_layer(input, num_input_channels,filter_size,num_filters,use_pooling=True)\n",
    "\n",
    "#shape of the tensorflow filter weights\n",
    "\n",
    "shape = [filter_Size,filter_size,num_input_channels,num_filters]\n",
    "\n",
    "#create new weights with the given shape\n",
    "weights = new_weights(shape=shape)\n",
    "\n",
    "#create new biases, one for each filter\n",
    "\n",
    "biases= new_biases(length=num_filters)\n",
    "\n",
    "#create the TF operation for convolution, strides set to 1 in all dimensions\n",
    "#first and last must be 1, first is for image number and last is inpu_channel\n",
    "#padding adds 0's to the sides so the outputs will be the same\n",
    "\n",
    "layer = tf.nn.conv2d(input=input\n",
    "                    filter=weights\n",
    "                    strides = [1,1,1,1]\n",
    "                    padding = 'SAME')\n",
    "#add the biases to the results of the convolution\n",
    "#now a bias value is added to each filter-channel\n",
    "layer+=biases\n",
    "\n",
    "#use pooling to downsample\n",
    "\n",
    "if use_pooling:\n",
    "    #2x2 maxpooling...means we take the largest value in the 2x2 window and\n",
    "    #and select it...then we move 2 pixels to the next window\n",
    "    layer= tf.nn.max_pool(value= layer\n",
    "                         ksize=[1,2,2,1]\n",
    "                         strides=[1,2,2,1]\n",
    "                         padding='SAME')\n",
    "    #adds non-linearity to the model by changing negative values to 0\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    #ReLU is normally executed before pooling\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    #the shape of the uinput layer is assumed to be:\n",
    "    #layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "    #,we can use a function from TF to calulate the features\n",
    "    num_features= layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    \n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "    \n",
    "    return layer_flat, num_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input,\n",
    "                 num_imputs #num imputs from the previous layer\n",
    "                 num_outputs \n",
    "                 use_relu=True)\n",
    "    #create new weights and biases\n",
    "    weights= new_weights(shape=[num_imputs,num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    \n",
    "    #calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values\n",
    "    layer= tf.matmul(input,weights) + biases\n",
    "    \n",
    "    #use ReLU\n",
    "    \n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder variables\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image\n",
    "                   num_input_channels=num_channels\n",
    "                   filter_size=filter_size1\n",
    "                   num_filters=num_filters1\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Layer2\n",
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten\n",
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully Connected Layer 1\n",
    "\n",
    "#Add a fully-connected layer to the network. The input is the flattened layer from the previous convolution. \n",
    "#The number of neurons or nodes in the fully-connected layer is fc_size. \n",
    "#ReLU is used so we can learn non-linear relations.\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                        num_inputs=num_features,\n",
    "                        num_outputs=fc_size,\n",
    "                        use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fully Connected Layer2\n",
    "#Add another fully-connected layer that outputs vectors of length 10 for determining which of the 10 classes the input image belongs to. \n",
    "#Note that ReLU is not used in this layer.\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                        num_inputs=fc_size,\n",
    "                        num_outputs=num_classes,\n",
    "                        use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to normalize the output of our 2nd fully connected layer so we add a softmax function\n",
    "y_pred= tf.nn.softmax(layer_fc2)\n",
    "\n",
    "#the class number is the index of the largest element\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost Function\n",
    "cross_entropy= tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                      labels=y_true)\n",
    "\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimization\n",
    "\n",
    "#This is a vector of booleans whether the predicted class equals the true class of each image.\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "\n",
    "#This calculates the classification accuracy by first type-casting the vector of booleans to floats, \n",
    "#so that False becomes 0 and True becomes 1, and then calculating the average of these numbers.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Tensorflow\n",
    "\n",
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to perform opitimization iterations\n",
    "\n",
    "train_batch_size=64\n",
    "\n",
    "#counter for total iterations performed\n",
    "total iterations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make an optimizer function\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    #make sure we update the global variable not a local copy\n",
    "    global total_iterations\n",
    "    \n",
    "    #Start-time used for printing time-usage\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(total_iterations, total_iterations +num_iterations):\n",
    "        #get a batch of training samples\n",
    "        #x_batch holds a batch of images and Y_true_batch are the true labels for those images\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "        \n",
    "        #put the batch into the dict with names for the placeholder variables\n",
    "        #in the TensorFlow Graph\n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "        \n",
    "        #run the optimizer using this batch of training data TensorFlow assigns the variables\n",
    "        #in feed_dict_train to the placeholder variables and then runs the optimizer\n",
    "        \n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        # print a status for every 100 iterations\n",
    "        if i%100 == 0:\n",
    "            #calculate the accuracy on the training-set\n",
    "            \n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            #message for printing\n",
    "            msg = 'Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}'\n",
    "            \n",
    "            #now print\n",
    "            print(msg.format(i +1), acc)\n",
    "            \n",
    "            #update the total number of iterations performed\n",
    "            total_iterations += num_iterations\n",
    "            \n",
    "            #ending time\n",
    "            end_time = time.time()\n",
    "            \n",
    "            #difference between the start and end times\n",
    "            time_dif = end_time - start_time\n",
    "            \n",
    "            print('Time Usage: ' + str(timedelta(seconds=int(round(time_dif)))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
